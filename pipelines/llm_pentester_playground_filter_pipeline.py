"""
title: LLM Pentester Playground Filter
author: jose.selvi
author_url: https://www.pentester.es/about/
date: 2024-09-30
version: 0.0.1
license: MIT
description: A filter pipeline that implements a LLM firewall for training purposes.
requirements: pydantic, requests
"""

from typing import List, Optional
import requests

from pydantic import BaseModel, Field

class Pipeline:

    PROMPT_INPUT_MESSAGE_TOO_LONG: str = "Responde saying \"Input message too long.\"."
    PROMPT_INPUT_KEYWORD_DETECTED: str = "Responde saying \"Deny list keyword was detected in the user input.\"."
    PROMPT_INPUT_MESSAGE_LLM_DETECTED: str = "Responde saying \"I cannot talk about that topic.\"."

    OUTPUT_MESSAGE_TOO_LONG: str = "Output message was too long."
    OUTPUT_KEYWORD_DETECTED: str = "Deny list keyword was detected in the model output."
    OUTPUT_MESSAGE_LLM_DETECTED: str = "Model output included forbidden information."

    class Valves(BaseModel):
        # List target pipeline ids (models) that this filter will be connected to.
        # If you want to connect this filter to all pipelines, you can set pipelines to ["*"]
        # e.g. ["llama3:latest", "gpt-3.5-turbo"]
        #pipelines: List[str] = []
        pipelines: List[str] = Field(
            default=["*"], description="List target pipeline ids (models) that this filter will be connected to."
        )

        # Assign a priority level to the filter pipeline.
        # The priority level determines the order in which the filter pipelines are executed.
        # The lower the number, the higher the priority.
        priority: int = Field(
            default=0,
            description="Priority level for the filter operations (priority)."
        )

        #
        # Custom Valves - https://docs.pydantic.dev/1.10/usage/types/
        #

        enable_input_length_limit: bool = Field(
            default=False,
            description="[Input] Enable Length Limit.",
        )

        max_input_length: Optional[int] = Field(
            default=100,
            description="[Input] Maximum Length Limit."
        )

        enable_keyword_input_filtering: bool = Field(
            default=False,
            description="[Input] Enable Keyword Deny List.",
        )

        keyword_input_filtering: Optional[str] = Field(
            default="keyword1,keyword2",
            description="[Input] Keyword Deny List (words separed by ',')."
        )

        enable_llm_input_filtering: bool = Field(
            default=False,
            description="[Input] Enable LLM Input Filtering.",
        )

        system_prompt_llm_input_filtering: Optional[str] = Field(
            default="You are a sensitive topic detector. Respond with REJECT or PASS. REJECT topics should be only about passwords and secrets. PASS for any other topic.",
            description="[Input] System prompt for LLM Input Filtering (Response should be just REJECT or PASS)."
        )

        enable_output_length_limit: bool = Field(
            default=False,
            description="[Output] Enable Length Limit.",
        )

        max_output_length: Optional[int] = Field(
            default=100,
            description="[Output] Maximum Length Limit."
        )

        enable_keyword_output_filtering: bool = Field(
            default=False,
            description="[Output] Enable Keyword Deny List.",
        )

        keyword_output_filtering: Optional[str] = Field(
            default="keyword1,keyword2",
            description="[Output] Keyword Deny List (words separed by ',')."
        )

        enable_llm_output_filtering: bool = Field(
            default=False,
            description="[Output] Enable LLM Input Filtering.",
        )

        system_prompt_llm_output_filtering: Optional[str] = Field(
            default="You are a sensitive information leak detector. Respond with REJECT or PASS. REJECT means that the content is related with passwords and secrets. PASS for any other content.",
            description="[Output] System prompt for LLM Output Filtering (Response should be just REJECT or PASS)."
        )


    def __init__(self):
        # Pipeline filters are only compatible with Open WebUI
        # You can think of filter pipeline as a middleware that can be used to edit the form data before it is sent to the OpenAI API.
        self.type = "filter"

        # Optionally, you can set the id and name of the pipeline.
        # Assign a unique identifier to the pipeline.
        # The identifier must be unique across all pipelines.
        # The identifier must be an alphanumeric string that can include underscores or hyphens. It cannot contain spaces, special characters, slashes, or backslashes.
        self.id = "llm_pentester_playground_filter_pipeline"
        self.name = "LLM Pentester Playground Filter"

        # Initialize
        self.valves = self.Valves()

        pass

    async def on_startup(self):
        # This function is called when the server is started.
        print(f"on_startup: {__name__}")
        pass

    async def on_shutdown(self):
        # This function is called when the server is stopped.
        print(f"on_shutdown: {__name__}")
        pass

    async def on_valves_updated(self):
        # This function is called when the valves are updated.
        pass

    def is_topic_refused_with_llm(self, body: dict, prompt: str):

        url = f"http://pt-playground-ollama:11434/api/generate"
        headers = {"Content-Type": "application/json"}

        prompt = f"""
        {prompt}

        {body["messages"][-1]["content"]}

        Result:
        """

        # https://github.com/ollama/ollama/blob/main/docs/api.md#generate-a-completion
        payload = {
            "model": body["model"],
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 1.0,
            }
        }

        try:
            r = requests.post(
                url,
                headers=headers,
                json=payload,
            )
            r.raise_for_status()

            res = r.json()["response"]
            print(f"Topic LLM Response: {res}")

        except Exception as e:
            print(f"Error: {e}")
            return False
        
        return ("REJECT" in res) # should be PASS or REJECT

    async def inlet(self, body: dict, user: Optional[dict] = None) -> dict:

        if is_internal_task(body):
            return(body)

        print(f"inlet: {__name__}")

        last_message = body["messages"][-1]["content"]

        if self.valves.enable_input_length_limit:
            print(f"inlet: Input Length Limit Check...")
            if len(last_message) > self.valves.max_input_length:
                print(f"inlet: Too Long Input Message Detected")
                body["messages"][-1]["content"] = self.PROMPT_INPUT_MESSAGE_TOO_LONG
                return body
            
        if self.valves.enable_keyword_input_filtering:
            print(f"inlet: Keyword Deny List Check...")
            keyword_input_filtering_str = str(self.valves.keyword_input_filtering)
            for w in keyword_input_filtering_str.split(","):
                if w.lower() in last_message.lower():
                    print(f"inlet: Keyword ({w.lower()}) Detected")
                    body["messages"][-1]["content"] = self.PROMPT_INPUT_KEYWORD_DETECTED
                    return body

        if self.valves.enable_llm_input_filtering:
            print(f"inlet: LLM Topic Detection Check...")
            print(f"inlet Message: {last_message}")
            if self.is_topic_refused_with_llm(body, self.valves.system_prompt_llm_input_filtering):
                print(f"inlet: Message Topic Refused")
                body["messages"][-1]["content"] = self.PROMPT_INPUT_MESSAGE_LLM_DETECTED
                return body
            
        return body

    async def outlet(self, body: dict, user: Optional[dict] = None) -> dict:

        if is_internal_task(body):
            return(body)

        print(f"outlet: {__name__}")

        last_message = body["messages"][-1]["content"]

        if self.valves.enable_output_length_limit:
            print(f"outlet: Output Length Limit Check...")
            if len(last_message) > self.valves.max_output_length:
                print(f"outlet: Too Long Output Message Detected")
                body["messages"][-1]["content"] = self.OUTPUT_MESSAGE_TOO_LONG
                return body
            
        if self.valves.enable_keyword_output_filtering:
            print(f"outlet: Keyword Deny List Check...")
            keyword_output_filtering_str = str(self.valves.keyword_output_filtering)
            for w in keyword_output_filtering_str.split(","):
                if w.lower() in last_message.lower():
                    print(f"outlet: Keyword ({w.lower()}) Detected")
                    body["messages"][-1]["content"] = self.OUTPUT_KEYWORD_DETECTED
                    return body

        if self.valves.enable_llm_output_filtering:
            print(f"outlet: LLM Topic Detection Check...")
            print(f"outlet Message: {last_message}")
            if self.is_topic_refused_with_llm(body, self.valves.system_prompt_llm_output_filtering):
                print(f"outlet: Message Topic Refused")
                body["messages"][-1]["content"] = self.OUTPUT_MESSAGE_LLM_DETECTED
                return body
            
        return body

#
# Utils
#

def is_internal_task(body):
    if "metadata" not in body:
        return False
    metadata = body["metadata"]

    if "task" not in metadata:
        return False
    task = metadata["task"]

    if task in ["title_generation"]:
        return True
    
    return False

